{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'constants'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score  \u001b[38;5;66;03m# Import accuracy_score\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_images  \u001b[38;5;66;03m# Assuming this function is defined in utils.py\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m entity_unit_map, allowed_units  \u001b[38;5;66;03m# Importing the unit map\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m  \u001b[38;5;66;03m# For image processing\u001b[39;00m\n",
      "File \u001b[1;32md:\\Projects\\Amazon-ML-Challenge-Team-AutoGen-\\student_resource 3\\src\\utils.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconstants\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'constants'"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pytesseract  # For OCR\n",
    "from PIL import Image  # For image processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score  # Import accuracy_score\n",
    "from src.utils import download_images  # Assuming this function is defined in utils.py\n",
    "from src.constants import entity_unit_map, allowed_units  # Importing the unit map\n",
    "import cv2  # For image processing\n",
    "import matplotlib.pyplot as plt  # For visualization\n",
    "import torch  # For BERT and PyTorch\n",
    "from transformers import BertTokenizer, BertForTokenClassification  # For BERT model\n",
    "from transformers import Trainer, TrainingArguments  # For training the model\n",
    "import random\n",
    "import re\n",
    "from transformers import EarlyStoppingCallback  # For callbacks\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 2: Load and Clean the Dataset\n",
    "# Load the training and test datasets\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "# Display total null values in the dataset\n",
    "print(\"Total null values in training dataset:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Replace null values in entity_value with a specified string\n",
    "train_df['entity_value'].fillna('', inplace=True)  # Replace NaN in entity_value with ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Download Images\n",
    "# Download images for both train and test datasets\n",
    "download_images(train_df['image_link'].tolist(), download_folder='dataset/train_images')\n",
    "download_images(test_df['image_link'].tolist(), download_folder='dataset/test_images')\n",
    "\n",
    "# Cell 4: Display Random Images with Entity Name and Value\n",
    "# Display 5 random images with their entity names and values\n",
    "def display_random_images(df, num_images=5):\n",
    "    random_samples = df.sample(num_images)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, (index, row) in enumerate(random_samples.iterrows()):\n",
    "        img_path = os.path.join('dataset/train_images', row['image_link'].split('/')[-1])\n",
    "        img = plt.imread(img_path)\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{row['entity_name']}: {row['entity_value']}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "display_random_images(train_df, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Group Data by Entity Name\n",
    "# Group the training data by entity_name\n",
    "grouped_train_df = train_df.groupby('entity_name')\n",
    "\n",
    "# Display the grouped data (optional)\n",
    "for name, group in grouped_train_df:\n",
    "    print(f\"Entity Name: {name}, Number of Samples: {len(group)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Prepare Data for Model Training\n",
    "# Create a mapping for allowed units and their abbreviations\n",
    "unit_abbreviations = {\n",
    "    # For 'item_weight' and 'maximum_weight_recommendation'\n",
    "    'gram': ['g', 'gr', 'gm', 'grams', 'grm'],\n",
    "    'kilogram': ['kg', 'kilograms', 'kgs'],\n",
    "    'milligram': ['mg', 'milligrams', 'mgs'],\n",
    "    'microgram': ['µg', 'mcg', 'micrograms'],\n",
    "    'ounce': ['oz', 'ounces', 'ozs'],\n",
    "    'pound': ['lb', 'lbs', 'pounds'],\n",
    "    'ton': ['t', 'tons', 'tonne', 'tonnes'],\n",
    "\n",
    "    # For 'item_volume'\n",
    "    'millilitre': ['ml', 'milliliters', 'millilitres'],\n",
    "    'litre': ['l', 'lit', 'liters', 'litres'],\n",
    "    'cubic_centimetre': ['cc', 'cm³', 'cubic centimeters', 'cubic centimetres'],\n",
    "    'cubic_metre': ['m³', 'cubic meters', 'cubic metres'],\n",
    "    'gallon': ['gal', 'gallons'],\n",
    "    'quart': ['qt', 'quarts'],\n",
    "    'pint': ['pt', 'pints'],\n",
    "    'cup': ['c', 'cups'],\n",
    "\n",
    "    # For 'voltage'\n",
    "    'volt': ['v', 'volts'],\n",
    "    'kilovolt': ['kv', 'kilovolts'],\n",
    "    'millivolt': ['mv', 'millivolts'],\n",
    "\n",
    "    # For 'wattage'\n",
    "    'watt': ['w', 'watts'],\n",
    "    'kilowatt': ['kw', 'kilowatts'],\n",
    "    'megawatt': ['mw', 'megawatts'],\n",
    "    'gigawatt': ['gw', 'gigawatts'],\n",
    "\n",
    "    # For 'height', 'depth', and 'width'\n",
    "    'millimetre': ['mm', 'millimeters', 'millimetres'],\n",
    "    'centimetre': ['cm', 'centimeters', 'centimetres'],\n",
    "    'metre': ['m', 'meters', 'metres'],\n",
    "    'kilometre': ['km', 'kilometers', 'kilometres'],\n",
    "    'inch': ['in', 'inches'],\n",
    "    'foot': ['ft', 'feet'],\n",
    "    'yard': ['yd', 'yards'],\n",
    "    'mile': ['mi', 'miles'],\n",
    "\n",
    "    # Other common units\n",
    "    'degree_celsius': ['°C', 'C', 'degrees Celsius'],\n",
    "    'degree_fahrenheit': ['°F', 'F', 'degrees Fahrenheit'],\n",
    "    'calorie': ['cal', 'calories'],\n",
    "    'kilocalorie': ['kcal', 'kcals'],\n",
    "    'joule': ['j', 'joules'],\n",
    "    'pascal': ['Pa', 'pascals'],\n",
    "    'bar': ['bar', 'bars'],\n",
    "    'psi': ['psi', 'pounds per square inch'],\n",
    "    'newton': ['N', 'newtons'],\n",
    "    'fluid_ounce': ['fl oz', 'fluid ounces'],\n",
    "}\n",
    "\n",
    "# Prepare the data for BERT encoding\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def create_labels(df):\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        entity_value = row['entity_value']\n",
    "        entity_name = row['entity_name']\n",
    "        \n",
    "        # Tokenize the entity value\n",
    "        tokens = tokenizer.tokenize(entity_value)\n",
    "        \n",
    "        # Create a label list for the tokens\n",
    "        label = []\n",
    "        for token in tokens:\n",
    "            if token in unit_abbreviations.get(entity_name, []):\n",
    "                label.append(1)  # Label for the unit (1 for unit)\n",
    "            else:\n",
    "                label.append(0)  # Label for non-unit (0 for non-unit)\n",
    "        \n",
    "        # Pad the label to match the maximum length\n",
    "        label += [0] * (tokenizer.model_max_length - len(label))\n",
    "        \n",
    "        # Append the label list to the labels\n",
    "        labels.append(label[:tokenizer.model_max_length])  # Ensure it doesn't exceed max length\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Generate the training labels\n",
    "train_labels = create_labels(train_df)\n",
    "\n",
    "# Prepare the encodings for training\n",
    "def encode_data(df):\n",
    "    return tokenizer(df['entity_value'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "train_encodings = encode_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define the Dataset Class\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EntityDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = EntityDataset(train_encodings, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Define the Model\n",
    "# Load BERT model for token classification\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(entity_unit_map))\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    ")\n",
    "\n",
    "# Create a Trainer instance with EarlyStoppingCallback\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Stop training if no improvement\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Train the Model\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model after training\n",
    "trainer.save_model('./saved_model')  # Specify the directory where you want to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Evaluate the Model\n",
    "# Evaluate the model on the training set\n",
    "train_predictions = trainer.predict(train_dataset)\n",
    "train_preds = np.argmax(train_predictions.predictions, axis=2)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report on Training Set:\")\n",
    "print(classification_report(train_labels, train_preds))\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(train_labels, train_preds)\n",
    "print(f\"Accuracy on Training Set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Make Predictions on Test Set\n",
    "# Prepare test data for predictions\n",
    "test_encodings = encode_data(test_df)\n",
    "\n",
    "# Create test labels (this is a placeholder; you need to define how to create labels)\n",
    "test_labels = create_labels(test_df)  # Generate test labels similarly\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = EntityDataset(test_encodings, test_labels)\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "test_preds = np.argmax(test_predictions.predictions, axis=2)\n",
    "\n",
    "# Integrate unit extraction into the prediction process\n",
    "def extract_text_from_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "def find_units_in_text(text, unit_abbreviations):\n",
    "    found_units = {}\n",
    "    for unit, abbreviations in unit_abbreviations.items():\n",
    "        for abbreviation in abbreviations:\n",
    "            if abbreviation in text:\n",
    "                found_units[unit] = abbreviation\n",
    "                break  # Stop checking once we find a match for this unit\n",
    "    return found_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Create Submission File\n",
    "# Create a DataFrame for submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'index': test_df['index'],\n",
    "    'prediction': [entity_unit_map[row['entity_name']][pred] for row, pred in zip(test_df.iterrows(), test_preds)],\n",
    "    'extracted_units': [find_units_in_text(extract_text_from_image(os.path.join('dataset/test_images', row['image_link'].split('/')[-1])), unit_abbreviations) for _, row in test_df.iterrows()]\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to process a single image\n",
    "def process_single_image(index):\n",
    "    row = test_df.iloc[index]\n",
    "    img_path = os.path.join('dataset/test_images', row['image_link'].split('/')[-1])\n",
    "    \n",
    "    # Extract text from the image\n",
    "    extracted_text = extract_text_from_image(img_path)\n",
    "    \n",
    "    # Find units in the extracted text\n",
    "    found_units = find_units_in_text(extracted_text, unit_abbreviations)\n",
    "    \n",
    "    # Get the prediction for this index\n",
    "    prediction = [entity_unit_map[row['entity_name']][pred] for pred in test_preds[index]]\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Image: {row['image_link']}\")\n",
    "    print(f\"Extracted Text: {extracted_text}\")\n",
    "    print(f\"Found Units: {found_units}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "\n",
    "# Example usage for a single image (e.g., the first image in the test set)\n",
    "process_single_image(0)  # Change the index to process a different image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
