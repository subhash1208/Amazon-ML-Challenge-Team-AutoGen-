{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:24: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Sudee\\AppData\\Local\\Temp\\ipykernel_25928\\771604961.py:24: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  sys.path.append(os.path.abspath(\"D:\\Projects\\Amazon-ML-Challenge-Team-AutoGen-\\student_resource 3\\src\"))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from transformers import LayoutLMTokenizer, LayoutLMForTokenClassification\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from albumentations import Compose, Resize, RandomCrop, RandomBrightnessContrast\n",
    "import torch  # For CUDA\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import mlflow  # For experiment tracking\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Assuming your script is in the same directory as src\n",
    "sys.path.append(os.path.abspath(\"D:\\Projects\\Amazon-ML-Challenge-Team-AutoGen-\\student_resource 3\\src\"))\n",
    "\n",
    "from utils import download_images  # Assuming this function is defined in utils.py\n",
    "from constants import entity_unit_map, allowed_units  # Importing the unit map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = 'dataset/train.csv'\n",
    "TEST_CSV = 'dataset/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(image_links, save_dir='images'):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    image_paths = []\n",
    "    for i, link in enumerate(image_links):\n",
    "        response = requests.get(link)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        image_path = os.path.join(save_dir, f'image_{i}.jpg')\n",
    "        image.save(image_path)\n",
    "        image_paths.append(image_path)\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "\n",
    "def preprocess_images(image_paths, target_size=(224, 224)):\n",
    "    augment = A.Compose([\n",
    "        A.Resize(height=target_size[0], width=target_size[1]),\n",
    "        A.RandomBrightnessContrast(p=0.2)\n",
    "    ])\n",
    "    \n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        # Open the image, convert to RGB, and convert to numpy array\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        # Apply the augmentations\n",
    "        augmented = augment(image=image)\n",
    "        images.append(augmented['image'])\n",
    "    \n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_images(image_paths):\n",
    "    texts = []\n",
    "    for path in image_paths:\n",
    "        image = Image.open(path)\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_abbreviations = {\n",
    "    # For 'item_weight' and 'maximum_weight_recommendation'\n",
    "    'gram': ['g', 'gr', 'gm', 'grams', 'grm'],\n",
    "    'kilogram': ['kg', 'kilograms', 'kgs'],\n",
    "    'milligram': ['mg', 'milligrams', 'mgs'],\n",
    "    'microgram': ['µg', 'mcg', 'micrograms'],\n",
    "    'ounce': ['oz', 'ounces', 'ozs'],\n",
    "    'pound': ['lb', 'lbs', 'pounds'],\n",
    "    'ton': ['t', 'tons', 'tonne', 'tonnes'],\n",
    "\n",
    "    # For 'item_volume'\n",
    "    'millilitre': ['ml', 'milliliters', 'millilitres'],\n",
    "    'litre': ['l', 'lit', 'liters', 'litres'],\n",
    "    'cubic_centimetre': ['cc', 'cm³', 'cubic centimeters', 'cubic centimetres'],\n",
    "    'cubic_metre': ['m³', 'cubic meters', 'cubic metres'],\n",
    "    'gallon': ['gal', 'gallons'],\n",
    "    'quart': ['qt', 'quarts'],\n",
    "    'pint': ['pt', 'pints'],\n",
    "    'cup': ['c', 'cups'],\n",
    "\n",
    "    # For 'voltage'\n",
    "    'volt': ['v', 'volts'],\n",
    "    'kilovolt': ['kv', 'kilovolts'],\n",
    "    'millivolt': ['mv', 'millivolts'],\n",
    "\n",
    "    # For 'wattage'\n",
    "    'watt': ['w', 'watts'],\n",
    "    'kilowatt': ['kw', 'kilowatts'],\n",
    "    'megawatt': ['mw', 'megawatts'],\n",
    "    'gigawatt': ['gw', 'gigawatts'],\n",
    "\n",
    "    # For 'height', 'depth', and 'width'\n",
    "    'millimetre': ['mm', 'millimeters', 'millimetres'],\n",
    "    'centimetre': ['cm', 'centimeters', 'centimetres'],\n",
    "    'metre': ['m', 'meters', 'metres'],\n",
    "    'kilometre': ['km', 'kilometers', 'kilometres'],\n",
    "    'inch': ['in', 'inches'],\n",
    "    'foot': ['ft', 'feet'],\n",
    "    'yard': ['yd', 'yards'],\n",
    "    'mile': ['mi', 'miles'],\n",
    "\n",
    "    # Other common units\n",
    "    'degree_celsius': ['°C', 'C', 'degrees Celsius'],\n",
    "    'degree_fahrenheit': ['°F', 'F', 'degrees Fahrenheit'],\n",
    "    'calorie': ['cal', 'calories'],\n",
    "    'kilocalorie': ['kcal', 'kcals'],\n",
    "    'joule': ['j', 'joules'],\n",
    "    'pascal': ['Pa', 'pascals'],\n",
    "    'bar': ['bar', 'bars'],\n",
    "    'psi': ['psi', 'pounds per square inch'],\n",
    "    'newton': ['N', 'newtons'],\n",
    "    'fluid_ounce': ['fl oz', 'fluid ounces'],\n",
    "}\n",
    "\n",
    "def standardize_unit(value, entity_name):\n",
    "    for unit, abbreviations in unit_abbreviations.items():\n",
    "        for abbr in abbreviations:\n",
    "            if re.search(r'\\b' + re.escape(abbr) + r'\\b', value):\n",
    "                standardized_value = re.sub(abbr, unit, value)\n",
    "                return standardized_value\n",
    "    return value  # If no abbreviation found, return the original value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_resnet_model(num_classes):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Mixed Precision\n",
    "    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "    tf.keras.mixed_precision.set_global_policy(policy)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_layoutlm_model(num_labels):\n",
    "    tokenizer = LayoutLMTokenizer.from_pretrained('microsoft/layoutlm-base-uncased')\n",
    "    model = LayoutLMForTokenClassification.from_pretrained('microsoft/layoutlm-base-uncased', num_labels=num_labels)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_resnet(model, images):\n",
    "    predictions = model.predict(images)\n",
    "    return np.argmax(predictions, axis=1)\n",
    "\n",
    "def predict_with_layoutlm(model, tokenizer, texts):\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')\n",
    "    outputs = model(**encodings)\n",
    "    return np.argmax(outputs.logits.detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(test_df, resnet_model, layoutlm_model, tokenizer):\n",
    "    image_links = test_df['image_link'].tolist()\n",
    "    image_paths = download_images(image_links)\n",
    "    images = preprocess_images(image_paths)\n",
    "    \n",
    "    # Feature Extraction with ResNet\n",
    "    resnet_predictions = predict_with_resnet(resnet_model, images)\n",
    "    \n",
    "    # Text Extraction and LayoutLM Predictions\n",
    "    texts = extract_text_from_images(image_paths)\n",
    "    cleaned_texts = [standardize_unit(text, None) for text in texts]  # Pass None for entity_name if not needed\n",
    "    layoutlm_predictions = predict_with_layoutlm(layoutlm_model, tokenizer, cleaned_texts)\n",
    "    \n",
    "    # Combine predictions\n",
    "    predictions = [f\"{resnet_pred} {layoutlm_pred}\" for resnet_pred, layoutlm_pred in zip(resnet_predictions, layoutlm_predictions)]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_training(train_df, model_save_path, batch_size=100, max_batches=1500):\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "\n",
    "    for batch in range(1, max_batches + 1):\n",
    "        print(f\"Processing batch {batch}...\")\n",
    "        \n",
    "        # Download and preprocess images for the current batch\n",
    "        image_links = train_df['image_link'].head(batch * batch_size).tolist()\n",
    "        image_paths = download_images(image_links)\n",
    "        images = preprocess_images(image_paths)\n",
    "        labels = train_df['entity_value'].head(batch * batch_size).values\n",
    "        \n",
    "        # Ensure labels are integers\n",
    "        labels = labels.astype(np.int32)\n",
    "        \n",
    "        # Create TensorFlow dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "        dataset = dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
    "        \n",
    "        # Split dataset into training and validation sets\n",
    "        dataset_size = batch * batch_size\n",
    "        validation_size = int(0.2 * dataset_size)\n",
    "        train_size = dataset_size - validation_size\n",
    "        \n",
    "        train_dataset = dataset.take(train_size)\n",
    "        validation_dataset = dataset.skip(train_size)\n",
    "        \n",
    "        # Initialize and compile the model\n",
    "        model = initialize_resnet_model(num_classes=30)\n",
    "        \n",
    "        # Learning Rate Scheduling\n",
    "        def lr_scheduler(epoch, lr):\n",
    "            if epoch < 10:\n",
    "                return lr\n",
    "            else:\n",
    "                return lr * tf.math.exp(-0.1)\n",
    "        \n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "            ModelCheckpoint(model_save_path, save_best_only=True, monitor='val_accuracy'),\n",
    "            LearningRateScheduler(lr_scheduler)\n",
    "        ]\n",
    "        \n",
    "        # Ensure that the data passed to the model is in the correct format\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            epochs=5,\n",
    "            validation_data=validation_dataset,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        accuracy = max(history.history['val_accuracy'])\n",
    "        print(f\"Batch {batch} Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = load_model(model_save_path)\n",
    "    \n",
    "    print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(test_df, predictions, submission_file='submission.csv'):\n",
    "    test_df['prediction'] = predictions\n",
    "    test_df.to_csv(submission_file, index=False)\n",
    "    print(f\"Predictions saved to {submission_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/Cast_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"d:\\python3.12\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"d:\\python3.12\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n\n  File \"d:\\python3.12\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Sudee\\AppData\\Local\\Temp\\ipykernel_25928\\2534985517.py\", line 11, in <module>\n\n  File \"C:\\Users\\Sudee\\AppData\\Local\\Temp\\ipykernel_25928\\425488394.py\", line 48, in cumulative_training\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 359, in _compute_loss\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 327, in compute_loss\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 611, in __call__\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 652, in call\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 56, in __call__\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\tree\\tree_api.py\", line 148, in map_structure\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\tree\\optree_impl.py\", line 79, in map_structure\n\n  File \"d:\\python3.12\\Lib\\site-packages\\optree\\ops.py\", line 747, in tree_map\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 57, in <lambda>\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\ops\\core.py\", line 822, in convert_to_tensor\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py\", line 132, in convert_to_tensor\n\nCast string to float is not supported\n\t [[{{node compile_loss/sparse_categorical_crossentropy/Cast_1}}]] [Op:__inference_one_step_on_iterator_64225]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(TEST_CSV)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Cumulative Training\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mcumulative_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize LayoutLM and ResNet models\u001b[39;00m\n\u001b[0;32m     14\u001b[0m tokenizer, layoutlm_model \u001b[38;5;241m=\u001b[39m initialize_layoutlm_model(num_labels\u001b[38;5;241m=\u001b[39mNUM_CLASSES)\n",
      "Cell \u001b[1;32mIn[65], line 48\u001b[0m, in \u001b[0;36mcumulative_training\u001b[1;34m(train_df, model_save_path, batch_size, max_batches, checkpoint_file)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lr \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     42\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     43\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     44\u001b[0m     ModelCheckpoint(model_save_path, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     45\u001b[0m     LearningRateScheduler(lr_scheduler)\n\u001b[0;32m     46\u001b[0m ]\n\u001b[1;32m---> 48\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[0;32m     56\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32md:\\python3.12\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\python3.12\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/Cast_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"d:\\python3.12\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"d:\\python3.12\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n\n  File \"d:\\python3.12\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\Sudee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Sudee\\AppData\\Local\\Temp\\ipykernel_25928\\2534985517.py\", line 11, in <module>\n\n  File \"C:\\Users\\Sudee\\AppData\\Local\\Temp\\ipykernel_25928\\425488394.py\", line 48, in cumulative_training\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 359, in _compute_loss\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 327, in compute_loss\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 611, in __call__\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 652, in call\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 56, in __call__\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\tree\\tree_api.py\", line 148, in map_structure\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\tree\\optree_impl.py\", line 79, in map_structure\n\n  File \"d:\\python3.12\\Lib\\site-packages\\optree\\ops.py\", line 747, in tree_map\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 57, in <lambda>\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\ops\\core.py\", line 822, in convert_to_tensor\n\n  File \"d:\\python3.12\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py\", line 132, in convert_to_tensor\n\nCast string to float is not supported\n\t [[{{node compile_loss/sparse_categorical_crossentropy/Cast_1}}]] [Op:__inference_one_step_on_iterator_64225]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Adjust NUM_CLASSES as needed\n",
    "    NUM_CLASSES = 30  # Example number of classes, adjust based on your task\n",
    "    model_save_path = 'best_model.keras'\n",
    "    \n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    test_df = pd.read_csv(TEST_CSV)\n",
    "    \n",
    "    # Cumulative Training\n",
    "    best_model = cumulative_training(train_df, model_save_path, batch_size=100)\n",
    "    \n",
    "    # Initialize LayoutLM and ResNet models\n",
    "    tokenizer, layoutlm_model = initialize_layoutlm_model(num_labels=NUM_CLASSES)\n",
    "    resnet_model = load_model(model_save_path, custom_objects={'ResNet50': ResNet50})\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = generate_predictions(test_df, resnet_model, layoutlm_model, tokenizer)\n",
    "    \n",
    "    # Save predictions\n",
    "    save_predictions(test_df, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
