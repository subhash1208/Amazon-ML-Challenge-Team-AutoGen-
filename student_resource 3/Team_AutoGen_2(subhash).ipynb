{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:24: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Sudee\\AppData\\Local\\Temp\\ipykernel_18324\\771604961.py:24: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  sys.path.append(os.path.abspath(\"D:\\Projects\\Amazon-ML-Challenge-Team-AutoGen-\\student_resource 3\\src\"))\n",
      "d:\\python3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from transformers import LayoutLMTokenizer, LayoutLMForTokenClassification\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from albumentations import Compose, Resize, RandomCrop, RandomBrightnessContrast\n",
    "import torch  # For CUDA\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import mlflow  # For experiment tracking\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Assuming your script is in the same directory as src\n",
    "sys.path.append(os.path.abspath(\"D:\\Projects\\Amazon-ML-Challenge-Team-AutoGen-\\student_resource 3\\src\"))\n",
    "\n",
    "from utils import download_images  # Assuming this function is defined in utils.py\n",
    "from constants import entity_unit_map, allowed_units  # Importing the unit map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = 'dataset/train.csv'\n",
    "TEST_CSV = 'dataset/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(image_links, save_dir='images', batch_id=0):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    image_paths = []\n",
    "    for i, link in enumerate(image_links):\n",
    "        image_name = f'image_{batch_id}_{i}.jpg'\n",
    "        image_path = os.path.join(save_dir, image_name)\n",
    "        \n",
    "        # Check if the image already exists (optional)\n",
    "        if not os.path.exists(image_path):\n",
    "            response = requests.get(link)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            image.save(image_path)\n",
    "        \n",
    "        image_paths.append(image_path)\n",
    "    \n",
    "    return image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "\n",
    "def preprocess_images(image_paths, target_size=(224, 224)):\n",
    "    augment = A.Compose([\n",
    "        A.Resize(height=target_size[0], width=target_size[1]),\n",
    "        A.RandomBrightnessContrast(p=0.2)\n",
    "    ])\n",
    "    \n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        # Open the image, convert to RGB, and convert to numpy array\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        # Apply the augmentations\n",
    "        augmented = augment(image=image)\n",
    "        images.append(augmented['image'])\n",
    "    \n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_images(image_paths):\n",
    "    texts = []\n",
    "    for path in image_paths:\n",
    "        image = Image.open(path)\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_abbreviations = {\n",
    "    # For 'item_weight' and 'maximum_weight_recommendation'\n",
    "    'gram': ['g', 'gr', 'gm', 'grams', 'grm'],\n",
    "    'kilogram': ['kg', 'kilograms', 'kgs'],\n",
    "    'milligram': ['mg', 'milligrams', 'mgs'],\n",
    "    'microgram': ['µg', 'mcg', 'micrograms'],\n",
    "    'ounce': ['oz', 'ounces', 'ozs'],\n",
    "    'pound': ['lb', 'lbs', 'pounds'],\n",
    "    'ton': ['t', 'tons', 'tonne', 'tonnes'],\n",
    "\n",
    "    # For 'item_volume'\n",
    "    'millilitre': ['ml', 'milliliters', 'millilitres'],\n",
    "    'litre': ['l', 'lit', 'liters', 'litres'],\n",
    "    'cubic_centimetre': ['cc', 'cm³', 'cubic centimeters', 'cubic centimetres'],\n",
    "    'cubic_metre': ['m³', 'cubic meters', 'cubic metres'],\n",
    "    'gallon': ['gal', 'gallons'],\n",
    "    'quart': ['qt', 'quarts'],\n",
    "    'pint': ['pt', 'pints'],\n",
    "    'cup': ['c', 'cups'],\n",
    "\n",
    "    # For 'voltage'\n",
    "    'volt': ['v', 'volts'],\n",
    "    'kilovolt': ['kv', 'kilovolts'],\n",
    "    'millivolt': ['mv', 'millivolts'],\n",
    "\n",
    "    # For 'wattage'\n",
    "    'watt': ['w', 'watts'],\n",
    "    'kilowatt': ['kw', 'kilowatts'],\n",
    "    'megawatt': ['mw', 'megawatts'],\n",
    "    'gigawatt': ['gw', 'gigawatts'],\n",
    "\n",
    "    # For 'height', 'depth', and 'width'\n",
    "    'millimetre': ['mm', 'millimeters', 'millimetres'],\n",
    "    'centimetre': ['cm', 'centimeters', 'centimetres'],\n",
    "    'metre': ['m', 'meters', 'metres'],\n",
    "    'kilometre': ['km', 'kilometers', 'kilometres'],\n",
    "    'inch': ['in', 'inches'],\n",
    "    'foot': ['ft', 'feet'],\n",
    "    'yard': ['yd', 'yards'],\n",
    "    'mile': ['mi', 'miles'],\n",
    "\n",
    "    # Other common units\n",
    "    'degree_celsius': ['°C', 'C', 'degrees Celsius'],\n",
    "    'degree_fahrenheit': ['°F', 'F', 'degrees Fahrenheit'],\n",
    "    'calorie': ['cal', 'calories'],\n",
    "    'kilocalorie': ['kcal', 'kcals'],\n",
    "    'joule': ['j', 'joules'],\n",
    "    'pascal': ['Pa', 'pascals'],\n",
    "    'bar': ['bar', 'bars'],\n",
    "    'psi': ['psi', 'pounds per square inch'],\n",
    "    'newton': ['N', 'newtons'],\n",
    "    'fluid_ounce': ['fl oz', 'fluid ounces'],\n",
    "}\n",
    "\n",
    "def standardize_unit(value, entity_name):\n",
    "    for unit, abbreviations in unit_abbreviations.items():\n",
    "        for abbr in abbreviations:\n",
    "            if re.search(r'\\b' + re.escape(abbr) + r'\\b', value):\n",
    "                standardized_value = re.sub(abbr, unit, value)\n",
    "                return standardized_value\n",
    "    return value  # If no abbreviation found, return the original value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_resnet_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='linear')(x)  # For regression\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Mixed Precision\n",
    "    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "    tf.keras.mixed_precision.set_global_policy(policy)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_layoutlm_model(num_labels):\n",
    "    tokenizer = LayoutLMTokenizer.from_pretrained('microsoft/layoutlm-base-uncased')\n",
    "    model = LayoutLMForTokenClassification.from_pretrained('microsoft/layoutlm-base-uncased', num_labels=num_labels)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_resnet(model, images):\n",
    "    predictions = model.predict(images)\n",
    "    return predictions.flatten()  # For regression, return raw predictions\n",
    "\n",
    "def predict_with_layoutlm(model, tokenizer, texts):\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')\n",
    "    outputs = model(**encodings)\n",
    "    return np.argmax(outputs.logits.detach().numpy(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(test_df, resnet_model, layoutlm_model, tokenizer):\n",
    "    image_links = test_df['image_link'].tolist()\n",
    "    image_paths = download_images(image_links)\n",
    "    images = preprocess_images(image_paths)\n",
    "    \n",
    "    # Feature Extraction with ResNet\n",
    "    resnet_predictions = predict_with_resnet(resnet_model, images)\n",
    "    \n",
    "    # Text Extraction and LayoutLM Predictions\n",
    "    texts = extract_text_from_images(image_paths)\n",
    "    cleaned_texts = [standardize_unit(text, None) for text in texts]  # Pass None for entity_name if not needed\n",
    "    layoutlm_predictions = predict_with_layoutlm(layoutlm_model, tokenizer, cleaned_texts)\n",
    "    \n",
    "    # Combine predictions\n",
    "    predictions = [f\"{resnet_pred} {layoutlm_pred}\" for resnet_pred, layoutlm_pred in zip(resnet_predictions, layoutlm_predictions)]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(test_df, predictions, submission_file='submission.csv'):\n",
    "    test_df['prediction'] = predictions\n",
    "    test_df.to_csv(submission_file, index=False)\n",
    "    print(f\"Predictions saved to {submission_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def cumulative_training(train_df, model_save_path, batch_size=100, max_batches=30):\n",
    "    best_mae = float('inf')  # Mean Absolute Error for regression\n",
    "    for batch in range(1, max_batches + 1):\n",
    "        print(f\"Processing batch {batch}...\")\n",
    "        \n",
    "        # Download and preprocess images for the current batch\n",
    "        image_links = train_df['image_link'].head(batch * batch_size).tolist()\n",
    "        image_paths = download_images(image_links, batch_id=batch)  # Pass batch_id\n",
    "        images = preprocess_images(image_paths)\n",
    "        \n",
    "        # Extract and process labels\n",
    "        labels = train_df['entity_value'].head(batch * batch_size).apply(lambda x: float(re.sub(r'[^\\d.]', '', x))).values\n",
    "        labels = labels[~np.isnan(labels)]  # Remove NaNs if any\n",
    "        \n",
    "        # Create TensorFlow dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "        dataset = dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
    "        \n",
    "        # Split dataset into training and validation sets\n",
    "        dataset_size = len(images)\n",
    "        validation_size = int(0.2 * dataset_size)\n",
    "        train_size = dataset_size - validation_size\n",
    "        \n",
    "        train_dataset = dataset.take(train_size)\n",
    "        validation_dataset = dataset.skip(train_size)\n",
    "        \n",
    "        # Initialize and compile the model for regression\n",
    "        model = initialize_resnet_model()\n",
    "        \n",
    "        # Learning Rate Scheduling\n",
    "        def lr_scheduler(epoch, lr):\n",
    "            if epoch < 10:\n",
    "                return lr\n",
    "            else:\n",
    "                return lr * tf.math.exp(-0.1)\n",
    "        \n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_mae', patience=3, restore_best_weights=True),\n",
    "            ModelCheckpoint(model_save_path, save_best_only=True, monitor='val_mae'),\n",
    "            LearningRateScheduler(lr_scheduler)\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            epochs=5,\n",
    "            validation_data=validation_dataset,  # Ensure validation data is provided\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        mae = min(history.history['val_mae'])\n",
    "        print(f\"Batch {batch} MAE: {mae:.4f}\")\n",
    "        \n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = load_model(model_save_path)\n",
    "    \n",
    "    print(f\"Best MAE: {best_mae:.4f}\")\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1...\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Adjust NUM_CLASSES as needed\n",
    "    NUM_CLASSES = 30  # Example number of classes, adjust based on your task\n",
    "    model_save_path = 'best_model.keras'\n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    test_df = pd.read_csv(TEST_CSV)\n",
    "    \n",
    "    # Cumulative Training\n",
    "    best_model = cumulative_training(train_df, model_save_path, batch_size=100)\n",
    "    \n",
    "    # Initialize LayoutLM and ResNet models\n",
    "    tokenizer, layoutlm_model = initialize_layoutlm_model(num_labels=NUM_CLASSES)\n",
    "    resnet_model = load_model(model_save_path)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = generate_predictions(test_df, resnet_model, layoutlm_model, tokenizer)\n",
    "    \n",
    "    # Save predictions\n",
    "    save_predictions(test_df, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
