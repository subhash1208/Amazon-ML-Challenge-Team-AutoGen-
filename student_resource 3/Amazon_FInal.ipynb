{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhGHaWc6ibzJ",
        "outputId": "15f2a3d8-fe06-435e-98e0-f106dea0e49e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-vision in d:\\python3.12\\lib\\site-packages (3.7.4)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in d:\\python3.12\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.19.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in d:\\python3.12\\lib\\site-packages (from google-cloud-vision) (2.34.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\python3.12\\lib\\site-packages (from google-cloud-vision) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in d:\\python3.12\\lib\\site-packages (from google-cloud-vision) (5.28.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in d:\\python3.12\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in d:\\python3.12\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\python3.12\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.66.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\python3.12\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (1.66.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\python3.12\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\python3.12\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\python3.12\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\python3.12\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python3.12\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\python3.12\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python3.12\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\python3.12\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "%pip install google-cloud-vision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FUYIsyg837ve"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import re\n",
        "from google.cloud import vision\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5UsgP95xxSD",
        "outputId": "1e3f96d0-0901-416c-8a02-d6e62e27155f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KCzHIsx-4Ai2"
      },
      "outputs": [],
      "source": [
        "# Initialize Google Vision client\n",
        "client = vision.ImageAnnotatorClient()\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (224, 224)\n",
        "NUM_CLASSES = 8\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "NUM_CLASSES = 8  # Adjust based on your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Cv28PDy54mMt"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the mapping of categories to unit types\n",
        "category_to_units = {\n",
        "    'item_weight': ['gram', 'kilogram', 'milligram', 'microgram', 'ounce', 'pound', 'ton'],\n",
        "    'item_volume': ['millilitre', 'litre', 'cubic_centimetre', 'cubic_metre', 'gallon', 'quart', 'pint', 'cup'],\n",
        "    'voltage': ['volt', 'kilovolt', 'millivolt'],\n",
        "    'wattage': ['watt', 'kilowatt', 'megawatt', 'gigawatt'],\n",
        "    'maximum_weight_recommendation': ['gram', 'kilogram', 'milligram', 'microgram', 'ounce', 'pound', 'ton'],\n",
        "    'height': ['millimetre', 'centimetre', 'metre', 'kilometre', 'inch', 'foot', 'yard', 'mile'],\n",
        "    'depth': ['millimetre', 'centimetre', 'metre', 'kilometre', 'inch', 'foot', 'yard', 'mile'],\n",
        "    'width': ['millimetre', 'centimetre', 'metre', 'kilometre', 'inch', 'foot', 'yard', 'mile']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p8B-Hi944oxf"
      },
      "outputs": [],
      "source": [
        "# Function to map predicted category to units\n",
        "def map_category_to_units(predicted_category):\n",
        "    if predicted_category in category_to_units:\n",
        "        return category_to_units[predicted_category]\n",
        "    return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t8zja6Lp4q8e"
      },
      "outputs": [],
      "source": [
        "def load_image_from_url(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        img_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
        "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image from URL: {e}\")\n",
        "        return None\n",
        "\n",
        "# OCR function using Google Vision API\n",
        "def extract_text_from_image_google_vision(image_path):\n",
        "    with open(image_path, 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "\n",
        "    image = vision.Image(content=content)\n",
        "    response = client.text_detection(image=image)\n",
        "    texts = response.text_annotations\n",
        "    if texts:\n",
        "        return texts[0].description  # Extract the most prominent text\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xJ5aNBF44tIo"
      },
      "outputs": [],
      "source": [
        "# Function to process extracted text and identify numerical values with units\n",
        "def process_extracted_text(text):\n",
        "    match = re.search(r'(\\d+\\.?\\d*)\\s*([a-zA-Z]+)', text)\n",
        "    if match:\n",
        "        value = match.group(1)  # e.g., 500\n",
        "        unit = match.group(2)  # e.g., g\n",
        "        return value, unit\n",
        "    return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VlXdgzIV4xKj"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CXXL9Slv4vMd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the LabelEncoder on the entity_name column\n",
        "label_encoder.fit(train_df['entity_name'])\n",
        "\n",
        "# Define the data generator function\n",
        "def data_generator(df, batch_size):\n",
        "    while True:\n",
        "        for i in range(0, len(df), batch_size):\n",
        "            batch_df = df.iloc[i:i + batch_size]\n",
        "            images = []\n",
        "            labels = []\n",
        "            for _, row in batch_df.iterrows():\n",
        "                img_url = row['image_link']\n",
        "                img = load_image_from_url(img_url)\n",
        "                if img is not None:\n",
        "                    img_resized = cv2.resize(img, IMAGE_SIZE)\n",
        "                    img_array = img_to_array(img_resized)\n",
        "                    images.append(img_array)\n",
        "                    labels.append(row['entity_name'])  # Store the string label\n",
        "\n",
        "            images = np.array(images)\n",
        "\n",
        "            # Encode string labels to integers\n",
        "            encoded_labels = label_encoder.transform(labels)\n",
        "\n",
        "            # Convert integer labels to categorical (one-hot encoded)\n",
        "            categorical_labels = to_categorical(encoded_labels, num_classes=NUM_CLASSES)\n",
        "\n",
        "            yield images, categorical_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP-l21-Uj3Jt",
        "outputId": "df274378-15c7-4c63-c474-5758b878b6b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 4)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UJLJ0w-dyO7i"
      },
      "outputs": [],
      "source": [
        "train_df=train_df.head(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v7EbGcKj-2E",
        "outputId": "4345aac6-09f0-48f4-d9a6-1b613fd7e6ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(131187, 4)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IauPLOEEyULM"
      },
      "outputs": [],
      "source": [
        "test_df=test_df.head(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6aTYMgHbo4b",
        "outputId": "39e096ef-9778-48f3-add3-77c9a9914a0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained ResNet50 model for image feature extraction\n",
        "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ncJPLSMJe_HQ"
      },
      "outputs": [],
      "source": [
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oVNlFzM1fCap"
      },
      "outputs": [],
      "source": [
        "# Define the combined model\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AjhRmDWAfFpH"
      },
      "outputs": [],
      "source": [
        "# Define data generators for training and validation\n",
        "train_generator = data_generator(train_df, BATCH_SIZE)\n",
        "val_generator = data_generator(test_df, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGOWTWEDlBYp",
        "outputId": "8a1afcc8-2e7b-4935-b0f8-59104d109303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.6982 - loss: 8.9016 - val_accuracy: 0.1666 - val_loss: 7.2162\n",
            "Epoch 2/10\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 2s/step - accuracy: 0.8294 - loss: 0.7478 - val_accuracy: 0.1672 - val_loss: 8.5347\n",
            "Epoch 3/10\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 2s/step - accuracy: 0.8622 - loss: 0.4608 - val_accuracy: 0.1688 - val_loss: 10.5319\n",
            "Epoch 4/10\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m676s\u001b[0m 2s/step - accuracy: 0.8883 - loss: 0.3180 - val_accuracy: 0.1800 - val_loss: 11.0704\n",
            "Epoch 5/10\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 2s/step - accuracy: 0.9003 - loss: 0.2851 - val_accuracy: 0.1805 - val_loss: 10.4253\n",
            "Epoch 6/10\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 2s/step - accuracy: 0.9047 - loss: 0.2636 - val_accuracy: 0.1849 - val_loss: 13.2601\n",
            "Epoch 7/10\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 2s/step - accuracy: 0.9190 - loss: 0.2221 - val_accuracy: 0.1741 - val_loss: 11.6877\n",
            "Epoch 8/10\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 2s/step - accuracy: 0.9205 - loss: 0.2047 - val_accuracy: 0.1788 - val_loss: 8.0104\n",
            "Epoch 9/10\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 2s/step - accuracy: 0.9261 - loss: 0.1917 - val_accuracy: 0.1823 - val_loss: 9.6682\n",
            "Epoch 10/10\n",
            "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 2s/step - accuracy: 0.9383 - loss: 0.1538 - val_accuracy: 0.1832 - val_loss: 9.6603\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_path = \"model_checkpoint.weights.h5\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, save_weights_only=True, save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=len(train_df) // BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps=len(test_df) // BATCH_SIZE,\n",
        "                    callbacks=[checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSJeMr9ZlQ4-",
        "outputId": "b914e1ea-8e52-4822-e1eb-2d5773694cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.9276\n",
            "Final Validation Accuracy: 0.1832\n"
          ]
        }
      ],
      "source": [
        "# Print the final training and validation accuracy\n",
        "final_train_accuracy = history.history['accuracy'][-1]  # Accuracy of the last epoch\n",
        "final_val_accuracy = history.history['val_accuracy'][-1]  # Validation accuracy of the last epoch\n",
        "\n",
        "print(f\"Final Training Accuracy: {final_train_accuracy:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NlJ8GC6rMbxG"
      },
      "outputs": [],
      "source": [
        "def predict_image_category(image_url):\n",
        "    # Load and preprocess the image\n",
        "    img = load_image_from_url(image_url)\n",
        "    if img is not None:\n",
        "        img_resized = cv2.resize(img, IMAGE_SIZE)\n",
        "        img_array = img_to_array(img_resized)\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Predict using the model\n",
        "        predictions = model.predict(img_array)\n",
        "        predicted_class = np.argmax(predictions, axis=1)  # Get the index of the max prediction\n",
        "        predicted_label = label_encoder.inverse_transform(predicted_class)[0]  # Convert back to label\n",
        "\n",
        "        print(f\"Predicted Category: {predicted_label}\")\n",
        "        return predicted_label\n",
        "    else:\n",
        "        print(\"Error loading image.\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3De3jFduNTc8"
      },
      "outputs": [],
      "source": [
        "def extract_text_tesseract(image_url):\n",
        "    img = load_image_from_url(image_url)\n",
        "    if img is not None:\n",
        "        text = pytesseract.image_to_string(img)\n",
        "        return text.strip()\n",
        "    return \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrEtGkOGNWxs",
        "outputId": "628a5c16-68f2-4510-fd82-19c75fd082af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "eW-aRa1INhZF"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "K6YjTRXbNo5T"
      },
      "outputs": [],
      "source": [
        "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bn3RrweNNrVr"
      },
      "outputs": [],
      "source": [
        "def predict_and_compare(image_url):\n",
        "    # Predict category using the model\n",
        "    predicted_category = predict_image_category(image_url)\n",
        "\n",
        "    # Extract text using Tesseract OCR\n",
        "    tesseract_text = extract_text_tesseract(image_url)\n",
        "    print(f\"Tesseract OCR Extracted Text: {tesseract_text}\")\n",
        "\n",
        "    # Compare results\n",
        "    print(f\"Predicted Category: {predicted_category}\")\n",
        "    print(f\"Tesseract Text: {tesseract_text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA-8xT6DOFhk",
        "outputId": "024700bc-48a5-4f82-a9cd-ee3cd2c7e246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Predicted Category: item_weight\n",
            "Tesseract OCR Extracted Text: PRAKTISCH UND EFFIKTIV\n",
            "\n",
            "fur eine Vielzahl an Grof&{en und Formen\n",
            "\n",
            "r) BSE) eae Hochwertiges\n",
            "mit Click-Verschluss g Polyester Gewebe\n",
            "\n",
            "AL bl Ean eta\n",
            "UV Stabil und mea cla ce\n",
            "\n",
            ") ORV TEY ate rear y 4\n",
            "danke sehr robustem /) wasserabweisende\n",
            "600D Oxford Polyester Ya iw sxe silos [Ue Ae\n",
            "Predicted Category: item_weight\n",
            "Tesseract Text: PRAKTISCH UND EFFIKTIV\n",
            "\n",
            "fur eine Vielzahl an Grof&{en und Formen\n",
            "\n",
            "r) BSE) eae Hochwertiges\n",
            "mit Click-Verschluss g Polyester Gewebe\n",
            "\n",
            "AL bl Ean eta\n",
            "UV Stabil und mea cla ce\n",
            "\n",
            ") ORV TEY ate rear y 4\n",
            "danke sehr robustem /) wasserabweisende\n",
            "600D Oxford Polyester Ya iw sxe silos [Ue Ae\n"
          ]
        }
      ],
      "source": [
        "image_url = 'https://m.media-amazon.com/images/I/81poV0Le5lL.jpg'  # Replace with actual image URL\n",
        "predict_and_compare(image_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCzXPv8xOKfe",
        "outputId": "e96fa0fe-5148-42fd-9864-ecc033603903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 3s (1,743 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install tesseract-ocr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1iAPFRDOsMK",
        "outputId": "ac825772-84da-4037-db7c-2f10b4399855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytesseract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "oD5HEDVzOz9x"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkb6t8uQO4cv",
        "outputId": "89ac3441-c153-463a-9fb3-8c01a7302908"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "# Save the entire model to an HDF5 file\n",
        "model_save_path = 'saved_model.h5'\n",
        "model.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLZyk3_JWTK9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
